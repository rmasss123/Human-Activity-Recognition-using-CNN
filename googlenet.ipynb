{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8158162,"sourceType":"datasetVersion","datasetId":4826238}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport tensorflow as tf","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-21T00:33:23.516243Z","iopub.execute_input":"2024-04-21T00:33:23.516605Z","iopub.status.idle":"2024-04-21T00:33:37.286942Z","shell.execute_reply.started":"2024-04-21T00:33:23.516577Z","shell.execute_reply":"2024-04-21T00:33:37.286009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Define image directories\ntrain_dir = '/kaggle/input/human-activity-image-data/har_structured/train'\ntest_dir = '/kaggle/input/human-activity-image-data/har_structured/test'\n\n# Define ImageDataGenerators for training and testing datasets\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,  # Rescale pixel values to [0, 1]\n    shear_range=0.2,\n    horizontal_flip=True,\n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Define batch size and image size\nbatch_size = 32\nimage_size = (224, 224)  # Target image size\n\n# Flow images from directories\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size = image_size,\n    batch_size=batch_size,\n    class_mode='categorical'  # for multi-class classification\n)\n\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size = image_size,\n    batch_size=batch_size,\n    class_mode='categorical'  # for multi-class classification\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T00:34:32.454426Z","iopub.execute_input":"2024-04-21T00:34:32.455540Z","iopub.status.idle":"2024-04-21T00:34:33.481701Z","shell.execute_reply.started":"2024-04-21T00:34:32.455504Z","shell.execute_reply":"2024-04-21T00:34:33.480784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\n\n# Get a batch of data from the generator\nimages, labels = next(train_generator)\n\nprint(labels.shape)\n# Get the class names from the directory names\nclass_names = list(train_generator.class_indices.keys())\nprint(train_generator.class_indices)\n# Visualize a sample image and its inferred label\nsample_index = 0  # Index of the sample image to visualize\nfor i in range(0, 5):\n    plt.imshow(images[i])\n    plt.title(\"Label: \" + class_names[labels[i].argmax()])\n    plt.axis(\"off\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T00:21:27.291244Z","iopub.execute_input":"2024-04-21T00:21:27.292353Z","iopub.status.idle":"2024-04-21T00:21:29.352067Z","shell.execute_reply.started":"2024-04-21T00:21:27.292312Z","shell.execute_reply":"2024-04-21T00:21:29.350959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, AveragePooling2D, Dropout, Flatten, Dense\nfrom tensorflow.keras.models import Model\n\ndef inception_module(x, filters):\n    \"\"\"Inception module implementation.\"\"\"\n    # 1x1 conv branch\n    branch1x1 = Conv2D(filters=filters[0], kernel_size=(1, 1), padding='same', activation='relu')(x)\n\n    # 3x3 conv branch\n    branch3x3 = Conv2D(filters=filters[1], kernel_size=(1, 1), padding='same', activation='relu')(x)\n    branch3x3 = Conv2D(filters=filters[2], kernel_size=(3, 3), padding='same', activation='relu')(branch3x3)\n\n    # 5x5 conv branch\n    branch5x5 = Conv2D(filters=filters[3], kernel_size=(1, 1), padding='same', activation='relu')(x)\n    branch5x5 = Conv2D(filters=filters[4], kernel_size=(5, 5), padding='same', activation='relu')(branch5x5)\n\n    # Max pooling branch\n    branch_pool = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(x)\n    branch_pool = Conv2D(filters=filters[5], kernel_size=(1, 1), padding='same', activation='relu')(branch_pool)\n\n    # Concatenate the outputs of all branches\n    outputs = concatenate([branch1x1, branch3x3, branch5x5, branch_pool], axis=-1)\n    return outputs\n\n# Define GoogLeNet model\ndef googlenet(input_shape, num_classes):\n    \"\"\"GoogLeNet model implementation.\"\"\"\n    inputs = Input(shape=input_shape)\n\n    x = Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2), padding='same', activation='relu')(inputs)\n    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n\n    x = Conv2D(filters=64, kernel_size=(1, 1), padding='same', activation='relu')(x)\n    x = Conv2D(filters=192, kernel_size=(3, 3), padding='same', activation='relu')(x)\n    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n\n    x = inception_module(x, filters=[64, 96, 128, 16, 32, 32])\n    x = inception_module(x, filters=[128, 128, 192, 32, 96, 64])\n    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n\n    x = inception_module(x, filters=[192, 96, 208, 16, 48, 64])\n    x = inception_module(x, filters=[160, 112, 224, 24, 64, 64])\n    x = inception_module(x, filters=[128, 128, 256, 24, 64, 64])\n    x = inception_module(x, filters=[112, 144, 288, 32, 64, 64])\n    x = inception_module(x, filters=[256, 160, 320, 32, 128, 128])\n    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n\n    x = inception_module(x, filters=[256, 160, 320, 32, 128, 128])\n    x = inception_module(x, filters=[384, 192, 384, 48, 128, 128])\n    \n    x = AveragePooling2D(pool_size=(7, 7), strides=(1, 1))(x)\n    x = Flatten()(x)\n    x = Dropout(0.4)(x)\n    outputs = Dense(num_classes, activation='softmax')(x)\n\n    model = Model(inputs, outputs)\n    return model\n\n# Create GoogLeNet model\ninput_shape = (224, 224, 3)  # Example input shape\nnum_classes = 15  # Number of output classes (ImageNet)\nmodel = googlenet(input_shape, num_classes)\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Print model summary\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-21T00:35:58.698386Z","iopub.execute_input":"2024-04-21T00:35:58.699111Z","iopub.status.idle":"2024-04-21T00:36:00.048797Z","shell.execute_reply.started":"2024-04-21T00:35:58.699076Z","shell.execute_reply":"2024-04-21T00:36:00.047683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\nfrom IPython.display import SVG\n\nplot_model(model, to_file='/kaggle/working/model_plot.png', \n                  show_shapes=True, show_layer_names=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T00:36:09.176134Z","iopub.execute_input":"2024-04-21T00:36:09.176887Z","iopub.status.idle":"2024-04-21T00:36:13.330206Z","shell.execute_reply.started":"2024-04-21T00:36:09.176848Z","shell.execute_reply":"2024-04-21T00:36:13.327909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nmomentum_value = 0.9\noptimizer = Adam(learning_rate=0.001, beta_1=momentum_value)\nmodel.compile(optimizer=optimizer,\n            loss='categorical_crossentropy',\n            metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-04-21T00:36:20.464840Z","iopub.execute_input":"2024-04-21T00:36:20.465812Z","iopub.status.idle":"2024-04-21T00:36:20.477560Z","shell.execute_reply.started":"2024-04-21T00:36:20.465772Z","shell.execute_reply":"2024-04-21T00:36:20.476529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfilepath = '/kaggle/working/model.keras'\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', \n                        verbose=1, save_best_only=True, mode='max')","metadata":{"execution":{"iopub.status.busy":"2024-04-21T00:36:23.734175Z","iopub.execute_input":"2024-04-21T00:36:23.735101Z","iopub.status.idle":"2024-04-21T00:36:23.741818Z","shell.execute_reply.started":"2024-04-21T00:36:23.735047Z","shell.execute_reply":"2024-04-21T00:36:23.740876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=4, restore_best_weights=True)\ncallbacks_list = [checkpoint, early]","metadata":{"execution":{"iopub.status.busy":"2024-04-21T00:36:27.745498Z","iopub.execute_input":"2024-04-21T00:36:27.745890Z","iopub.status.idle":"2024-04-21T00:36:27.751381Z","shell.execute_reply.started":"2024-04-21T00:36:27.745859Z","shell.execute_reply":"2024-04-21T00:36:27.750021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_generator,\n    epochs=2,\n    validation_data=test_generator,\n    callbacks=callbacks_list\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T00:38:36.869547Z","iopub.execute_input":"2024-04-21T00:38:36.870027Z","iopub.status.idle":"2024-04-21T00:45:17.169903Z","shell.execute_reply.started":"2024-04-21T00:38:36.869963Z","shell.execute_reply":"2024-04-21T00:45:17.168934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training plots\nmodel.save('/kaggle/working/model_final.keras')\nepochs = [i for i in range(1, len(history.history['loss'])+1)]\n\nplt.plot(epochs, history.history['loss'], color='blue', label=\"training_loss\")\nplt.plot(epochs, history.history['val_loss'], color='red', label=\"validation_loss\")\nplt.legend(loc='best')\nplt.title('training')\nplt.xlabel('epoch')\n# plt.savefig(TRAINING_PLOT_FILE, bbox_inches='tight')\nplt.show()\n\nplt.plot(epochs, history.history['accuracy'], color='blue', label=\"training_accuracy\")\nplt.plot(epochs, history.history['val_accuracy'], color='red',label=\"validation_accuracy\")\nplt.legend(loc='best')\nplt.title('validation')\nplt.xlabel('epoch')\n# plt.savefig(VALIDATION_PLOT_FILE, bbox_inches='tight')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-21T01:22:11.616681Z","iopub.execute_input":"2024-04-21T01:22:11.617080Z","iopub.status.idle":"2024-04-21T01:22:12.684535Z","shell.execute_reply.started":"2024-04-21T01:22:11.617053Z","shell.execute_reply":"2024-04-21T01:22:12.683432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#make sure to load the best model\nfrom tensorflow.keras.models import load_model\nmodel = load_model('/kaggle/working/model_final.keras')\n\npredictions = model.predict(test_generator, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-21T01:22:43.870886Z","iopub.execute_input":"2024-04-21T01:22:43.871728Z"},"trusted":true},"execution_count":null,"outputs":[]}]}